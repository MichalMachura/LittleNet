{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install brevitas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xtnQT_6mBq52"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append('..')\n",
    "# from .. \n",
    "import metrics, preprocessing, utils, training\n",
    "import numpy as np\n",
    "\n",
    "preprocessing.BaseGenerator.MAX_NUMBER_OF_THREADS = 2\n",
    "preprocessing.YoloDataGenerator.NUMBER_OF_THREADS = 1\n",
    "\n",
    "metrics.CONSTANTS.OLD_TORCH = True\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dataset_local_path = '../../DATASETS/Merged_dataset'\n",
    "folds = training.load_folds('../folds_state_path_bbox.pkl')\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.conv.weight torch.Size([6, 1, 3, 3])\n",
      "0.bn.weight torch.Size([6])\n",
      "0.bn.bias torch.Size([6])\n",
      "0.bn.running_mean torch.Size([6])\n",
      "0.bn.running_var torch.Size([6])\n",
      "0.bn.num_batches_tracked torch.Size([])\n",
      "1.conv.weight torch.Size([8, 6, 1, 1])\n",
      "1.conv.bias torch.Size([8])\n",
      "1.bn.weight torch.Size([8])\n",
      "1.bn.bias torch.Size([8])\n",
      "1.bn.running_mean torch.Size([8])\n",
      "1.bn.running_var torch.Size([8])\n",
      "1.bn.num_batches_tracked torch.Size([])\n",
      "2.conv.weight torch.Size([8, 1, 3, 3])\n",
      "2.conv.bias torch.Size([8])\n",
      "2.bn.weight torch.Size([8])\n",
      "2.bn.bias torch.Size([8])\n",
      "2.bn.running_mean torch.Size([8])\n",
      "2.bn.running_var torch.Size([8])\n",
      "2.bn.num_batches_tracked torch.Size([])\n",
      "3.conv.weight torch.Size([16, 1, 3, 3])\n",
      "3.bn.weight torch.Size([16])\n",
      "3.bn.bias torch.Size([16])\n",
      "3.bn.running_mean torch.Size([16])\n",
      "3.bn.running_var torch.Size([16])\n",
      "3.bn.num_batches_tracked torch.Size([])\n",
      "4.conv.weight torch.Size([32, 16, 1, 1])\n",
      "4.conv.bias torch.Size([32])\n",
      "4.bn.weight torch.Size([32])\n",
      "4.bn.bias torch.Size([32])\n",
      "4.bn.running_mean torch.Size([32])\n",
      "4.bn.running_var torch.Size([32])\n",
      "4.bn.num_batches_tracked torch.Size([])\n",
      "5.conv.weight torch.Size([32, 1, 3, 3])\n",
      "5.conv.bias torch.Size([32])\n",
      "5.bn.weight torch.Size([32])\n",
      "5.bn.bias torch.Size([32])\n",
      "5.bn.running_mean torch.Size([32])\n",
      "5.bn.running_var torch.Size([32])\n",
      "5.bn.num_batches_tracked torch.Size([])\n",
      "6.conv.weight torch.Size([64, 1, 3, 3])\n",
      "6.bn.weight torch.Size([64])\n",
      "6.bn.bias torch.Size([64])\n",
      "6.bn.running_mean torch.Size([64])\n",
      "6.bn.running_var torch.Size([64])\n",
      "6.bn.num_batches_tracked torch.Size([])\n",
      "7.conv.weight torch.Size([64, 64, 1, 1])\n",
      "7.bn.weight torch.Size([64])\n",
      "7.bn.bias torch.Size([64])\n",
      "7.bn.running_mean torch.Size([64])\n",
      "7.bn.running_var torch.Size([64])\n",
      "7.bn.num_batches_tracked torch.Size([])\n",
      "8.conv.weight torch.Size([64, 1, 3, 3])\n",
      "8.conv.bias torch.Size([64])\n",
      "8.bn.weight torch.Size([64])\n",
      "8.bn.bias torch.Size([64])\n",
      "8.bn.running_mean torch.Size([64])\n",
      "8.bn.running_var torch.Size([64])\n",
      "8.bn.num_batches_tracked torch.Size([])\n",
      "9.conv.weight torch.Size([128, 1, 3, 3])\n",
      "9.conv.bias torch.Size([128])\n",
      "9.bn.weight torch.Size([128])\n",
      "9.bn.bias torch.Size([128])\n",
      "9.bn.running_mean torch.Size([128])\n",
      "9.bn.running_var torch.Size([128])\n",
      "9.bn.num_batches_tracked torch.Size([])\n",
      "10.conv.weight torch.Size([128, 128, 1, 1])\n",
      "10.bn.weight torch.Size([128])\n",
      "10.bn.bias torch.Size([128])\n",
      "10.bn.running_mean torch.Size([128])\n",
      "10.bn.running_var torch.Size([128])\n",
      "10.bn.num_batches_tracked torch.Size([])\n",
      "11.conv.weight torch.Size([128, 1, 3, 3])\n",
      "11.conv.bias torch.Size([128])\n",
      "11.bn.weight torch.Size([128])\n",
      "11.bn.bias torch.Size([128])\n",
      "11.bn.running_mean torch.Size([128])\n",
      "11.bn.running_var torch.Size([128])\n",
      "11.bn.num_batches_tracked torch.Size([])\n",
      "12.conv.weight torch.Size([256, 1, 3, 3])\n",
      "12.conv.bias torch.Size([256])\n",
      "12.bn.weight torch.Size([256])\n",
      "12.bn.bias torch.Size([256])\n",
      "12.bn.running_mean torch.Size([256])\n",
      "12.bn.running_var torch.Size([256])\n",
      "12.bn.num_batches_tracked torch.Size([])\n",
      "13.conv.weight torch.Size([256, 256, 1, 1])\n",
      "13.conv.bias torch.Size([256])\n",
      "13.bn.weight torch.Size([256])\n",
      "13.bn.bias torch.Size([256])\n",
      "13.bn.running_mean torch.Size([256])\n",
      "13.bn.running_var torch.Size([256])\n",
      "13.bn.num_batches_tracked torch.Size([])\n",
      "14.conv.weight torch.Size([256, 1, 3, 3])\n",
      "14.conv.bias torch.Size([256])\n",
      "14.bn.weight torch.Size([256])\n",
      "14.bn.bias torch.Size([256])\n",
      "14.bn.running_mean torch.Size([256])\n",
      "14.bn.running_var torch.Size([256])\n",
      "14.bn.num_batches_tracked torch.Size([])\n",
      "15.conv.weight torch.Size([512, 1, 3, 3])\n",
      "15.conv.bias torch.Size([512])\n",
      "15.bn.weight torch.Size([512])\n",
      "15.bn.bias torch.Size([512])\n",
      "15.bn.running_mean torch.Size([512])\n",
      "15.bn.running_var torch.Size([512])\n",
      "15.bn.num_batches_tracked torch.Size([])\n",
      "16.conv.weight torch.Size([256, 512, 1, 1])\n",
      "16.conv.bias torch.Size([256])\n",
      "16.bn.weight torch.Size([256])\n",
      "16.bn.bias torch.Size([256])\n",
      "16.bn.running_mean torch.Size([256])\n",
      "16.bn.running_var torch.Size([256])\n",
      "16.bn.num_batches_tracked torch.Size([])\n",
      "17.conv.weight torch.Size([256, 1, 3, 3])\n",
      "17.bn.weight torch.Size([256])\n",
      "17.bn.bias torch.Size([256])\n",
      "17.bn.running_mean torch.Size([256])\n",
      "17.bn.running_var torch.Size([256])\n",
      "17.bn.num_batches_tracked torch.Size([])\n",
      "18.conv.weight torch.Size([15, 256, 1, 1])\n",
      "18.conv.bias torch.Size([15])\n",
      "0 out_order tensor([0, 2, 4, 1, 3, 5])\n",
      "1 out_order tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "2 out_order tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "3 out_order tensor([ 0,  2,  4,  6,  8, 10, 12, 14,  1,  3,  5,  7,  9, 11, 13, 15])\n",
      "4 out_order tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "5 out_order tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "6 out_order tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
      "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62,  1,  3,  5,  7,\n",
      "         9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43,\n",
      "        45, 47, 49, 51, 53, 55, 57, 59, 61, 63])\n",
      "7 out_order tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "8 out_order tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "9 out_order tensor([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
      "         28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,\n",
      "         56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,  82,\n",
      "         84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104, 106, 108, 110,\n",
      "        112, 114, 116, 118, 120, 122, 124, 126,   1,   3,   5,   7,   9,  11,\n",
      "         13,  15,  17,  19,  21,  23,  25,  27,  29,  31,  33,  35,  37,  39,\n",
      "         41,  43,  45,  47,  49,  51,  53,  55,  57,  59,  61,  63,  65,  67,\n",
      "         69,  71,  73,  75,  77,  79,  81,  83,  85,  87,  89,  91,  93,  95,\n",
      "         97,  99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123,\n",
      "        125, 127])\n",
      "10 out_order tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "11 out_order tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "12 out_order tensor([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
      "         28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,\n",
      "         56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,  82,\n",
      "         84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104, 106, 108, 110,\n",
      "        112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138,\n",
      "        140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166,\n",
      "        168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194,\n",
      "        196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222,\n",
      "        224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250,\n",
      "        252, 254,   1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,\n",
      "         25,  27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
      "         53,  55,  57,  59,  61,  63,  65,  67,  69,  71,  73,  75,  77,  79,\n",
      "         81,  83,  85,  87,  89,  91,  93,  95,  97,  99, 101, 103, 105, 107,\n",
      "        109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135,\n",
      "        137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163,\n",
      "        165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191,\n",
      "        193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219,\n",
      "        221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247,\n",
      "        249, 251, 253, 255])\n",
      "13 out_order tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "14 out_order tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "15 out_order tensor([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
      "         28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,\n",
      "         56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,  82,\n",
      "         84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104, 106, 108, 110,\n",
      "        112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138,\n",
      "        140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166,\n",
      "        168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194,\n",
      "        196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222,\n",
      "        224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250,\n",
      "        252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278,\n",
      "        280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306,\n",
      "        308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330, 332, 334,\n",
      "        336, 338, 340, 342, 344, 346, 348, 350, 352, 354, 356, 358, 360, 362,\n",
      "        364, 366, 368, 370, 372, 374, 376, 378, 380, 382, 384, 386, 388, 390,\n",
      "        392, 394, 396, 398, 400, 402, 404, 406, 408, 410, 412, 414, 416, 418,\n",
      "        420, 422, 424, 426, 428, 430, 432, 434, 436, 438, 440, 442, 444, 446,\n",
      "        448, 450, 452, 454, 456, 458, 460, 462, 464, 466, 468, 470, 472, 474,\n",
      "        476, 478, 480, 482, 484, 486, 488, 490, 492, 494, 496, 498, 500, 502,\n",
      "        504, 506, 508, 510,   1,   3,   5,   7,   9,  11,  13,  15,  17,  19,\n",
      "         21,  23,  25,  27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,\n",
      "         49,  51,  53,  55,  57,  59,  61,  63,  65,  67,  69,  71,  73,  75,\n",
      "         77,  79,  81,  83,  85,  87,  89,  91,  93,  95,  97,  99, 101, 103,\n",
      "        105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131,\n",
      "        133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159,\n",
      "        161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187,\n",
      "        189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215,\n",
      "        217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243,\n",
      "        245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271,\n",
      "        273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299,\n",
      "        301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327,\n",
      "        329, 331, 333, 335, 337, 339, 341, 343, 345, 347, 349, 351, 353, 355,\n",
      "        357, 359, 361, 363, 365, 367, 369, 371, 373, 375, 377, 379, 381, 383,\n",
      "        385, 387, 389, 391, 393, 395, 397, 399, 401, 403, 405, 407, 409, 411,\n",
      "        413, 415, 417, 419, 421, 423, 425, 427, 429, 431, 433, 435, 437, 439,\n",
      "        441, 443, 445, 447, 449, 451, 453, 455, 457, 459, 461, 463, 465, 467,\n",
      "        469, 471, 473, 475, 477, 479, 481, 483, 485, 487, 489, 491, 493, 495,\n",
      "        497, 499, 501, 503, 505, 507, 509, 511])\n",
      "16 out_order tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "17 out_order tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "18 out_order tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "class DWConv2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,in_ch,intermediate_channels=1, bias=False, use_bn=True, use_relu=False, device=None):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch,in_ch*intermediate_channels,3,padding=1, groups=in_ch, bias=bias)\n",
    "        self.mul = intermediate_channels\n",
    "        self.reordered = False\n",
    "        \n",
    "        if use_bn:\n",
    "            self.bn = torch.nn.BatchNorm2d(in_ch*intermediate_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        if use_relu:\n",
    "            self.relu = torch.nn.ReLU(True)\n",
    "        else:\n",
    "            self.relu = None\n",
    "    \n",
    "    def reorder(self, order:torch.tensor):\n",
    "        conv = self.conv\n",
    "        ch_in = self.conv.in_channels\n",
    "        ch_out = self.conv.out_channels\n",
    "        mul = ch_out // ch_in\n",
    "        \n",
    "        indeces = []\n",
    "        for i in range(mul):\n",
    "            ind = torch.arange(0,ch_in)*mul+i\n",
    "            ind = ind[order]\n",
    "            \n",
    "            indeces.append(ind)\n",
    "        indeces = torch.cat(indeces)\n",
    "        \n",
    "        w = conv.weight[indeces,...]\n",
    "        b = conv.bias[indeces,...] if conv.bias is not None else None\n",
    "        L = torch.nn.Conv2d(ch_in*mul,ch_in*mul,3,padding=1, groups=ch_in*mul, bias=(b is not None))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            L.weight[...] = w\n",
    "            if b is not None:\n",
    "                print(\"no bias\")\n",
    "                L.bias[...] = b\n",
    "        \n",
    "        del self.conv\n",
    "        self.conv = L\n",
    "        \n",
    "        if self.bn is not None:\n",
    "            with torch.no_grad():\n",
    "                self.bn.weight[...] = self.bn.weight[indeces,...]\n",
    "                self.bn.bias[...] = self.bn.bias[indeces,...]\n",
    "                self.bn.running_mean[...] = self.bn.running_mean[indeces,...]\n",
    "                self.bn.running_var[...] = self.bn.running_var[indeces,...]\n",
    "        \n",
    "        self.reordered = True\n",
    "        \n",
    "        return indeces\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.reordered:\n",
    "            y = x\n",
    "            for i in range(self.mul-1):\n",
    "                y = torch.cat((y,x),dim=1)\n",
    "            x = y\n",
    "            \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class PWConv2d(torch.nn.Module):\n",
    "    def __init__(self,in_ch, out_ch, bias=False, use_bn=True, use_relu=False, use_mp=False, device=None):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch,out_ch,1,padding=0, bias=bias)\n",
    "    \n",
    "        if use_bn:\n",
    "            self.bn = torch.nn.BatchNorm2d(out_ch)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        if use_relu:\n",
    "            self.relu = torch.nn.ReLU(True)\n",
    "        else:\n",
    "            self.relu = None\n",
    "        if use_mp:\n",
    "            self.mp = torch.nn.MaxPool2d(2,2)\n",
    "        else:\n",
    "            self.mp = None\n",
    "    \n",
    "    def reorder(self, order:torch.tensor):\n",
    "        conv = self.conv\n",
    "        ch_in = self.conv.in_channels\n",
    "        ch_out = self.conv.out_channels\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[...] = self.conv.weight[:,order,...] \n",
    "        \n",
    "        return torch.arange(0,ch_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "        if self.mp:\n",
    "            x = self.mp(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class AnchorMul(torch.nn.Module):\n",
    "    def __init__(self, num_of_anchors, device=torch.device('cpu')):\n",
    "        super().__init__()\n",
    "        self.noa = num_of_anchors\n",
    "        self.anchors = torch.nn.Parameter(data=torch.Tensor(1,2*self.noa,1,1), requires_grad=True)\n",
    "        self.anchors.data.uniform_(-1,1)\n",
    "        self.register_parameter('anchors', self.anchors)\n",
    "        \n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xvc = x[:,:-2*self.noa,:,:]\n",
    "        xwh = x[:,-2*self.noa:,:,:]\n",
    "        ywh = xwh*torch.exp(self.anchors)\n",
    "        y = torch.cat((xvc,ywh), dim=1)\n",
    "\n",
    "        return y\n",
    "\n",
    "# float LN7\n",
    "net = torch.nn.Sequential(\n",
    "            DWConv2d(3, intermediate_channels=2, bias=False, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(6,8, bias=True, use_bn=True, use_relu=False, use_mp=True, device=device),\n",
    "            DWConv2d(8, bias=True, use_bn=True, use_relu=False, device=device),\n",
    "            DWConv2d(8, intermediate_channels=2, bias=False, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(16,32, bias=True, use_bn=True, use_relu=False, use_mp=True, device=device),\n",
    "            DWConv2d(32, bias=True, use_bn=True, use_relu=False, device=device),\n",
    "            DWConv2d(32, intermediate_channels=2, bias=False, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(64,64, bias=False, use_bn=True, use_relu=False, use_mp=True, device=device),\n",
    "            DWConv2d(64, bias=True, use_bn=True, use_relu=False, device=device),\n",
    "            DWConv2d(64, intermediate_channels=2, bias=True, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(128,128, bias=False, use_bn=True, use_relu=True, use_mp=True, device=device),\n",
    "            DWConv2d(128, bias=True, use_bn=True, use_relu=False, device=device),\n",
    "            DWConv2d(128, intermediate_channels=2, bias=True, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(256,256, bias=True, use_bn=True, use_relu=True, device=device),\n",
    "            DWConv2d(256, bias=True, use_bn=True, use_relu=False, device=device),\n",
    "            DWConv2d(256, intermediate_channels=2, bias=True, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(512,256, bias=True, use_bn=True, use_relu=True, device=device),\n",
    "            DWConv2d(256, intermediate_channels=1, bias=False, use_bn=True, use_relu=True, device=device),\n",
    "            PWConv2d(256,5*3, bias=True, use_bn=False, use_relu=False, device=device)\n",
    ").to(device)\n",
    "anchor_mul = AnchorMul(3,device).to(device)\n",
    "\n",
    "sd = torch.load('weights_float_gciou.pt',map_location=device)\n",
    "k = list(sd.keys())\n",
    "v = list(sd.values())\n",
    "# load anchor mul\n",
    "am_sd = {list(anchor_mul.state_dict().keys())[0]:v[-1]}\n",
    "anchor_mul.load_state_dict(am_sd)\n",
    "# load LN7 weights\n",
    "k = list(net.state_dict().keys()) # net keys\n",
    "net_sd = {k:v for k,v in zip(k,v[:-1])}\n",
    "net.load_state_dict(net_sd)\n",
    "\n",
    "net = net.eval()\n",
    "anchor_mul = anchor_mul.eval()\n",
    "\n",
    "for k,v in net.state_dict().items():\n",
    "    print(k,v.shape)\n",
    "\n",
    "order = torch.arange(0,3)\n",
    "\n",
    "renet = net\n",
    "for n,m in renet.named_children():\n",
    "#     print(n,\"in_order\", order)\n",
    "    order = m.reorder(order)\n",
    "    print(n,\"out_order\", order)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape = torch.Size([8, 3, 112, 208])\n",
      "Result shape = torch.Size([8, 15, 7, 13])\n",
      "Anchors: \n",
      "[[ 7.247059  10.725    ]\n",
      " [ 1.6470588  3.25     ]\n",
      " [ 4.9411764  1.625    ]]\n",
      "Output sizes: \n",
      "[13  7]\n"
     ]
    }
   ],
   "source": [
    "image_shape = (112, 208, 3)\n",
    "\n",
    "after_load = preprocessing.numpy_to_torch_iou_params(device)\n",
    "to_anchors_single = lambda *x: preprocessing.to_anchors_for_iou_loss(*x,False,False)\n",
    "# to_anchors_multi = lambda *x: preprocessing.to_anchors_for_iou_loss(*x,True,True)\n",
    "to_anchors_multi = lambda *x: preprocessing.to_anchors_for_iou_loss(*x,True,False)\n",
    "# to_anchors_single = to_anchors_multi\n",
    "\n",
    "anchors = [22,33,\n",
    "            5,10,\n",
    "            15,5\n",
    "          ]\n",
    "anchors = np.array(anchors, np.float32).reshape((-1,2))\n",
    "anchors *= np.array([[image_shape[0]/340, image_shape[1]/640]])\n",
    "\n",
    "# pass example tensor\n",
    "torch.cuda.empty_cache()\n",
    "tensor = torch.rand((8,3,)+image_shape[:2]).to(device)\n",
    "print(\"Input shape =\",tensor.shape)\n",
    "with torch.no_grad():\n",
    "    result = net(tensor)\n",
    "\n",
    "print(\"Result shape =\",result.shape)\n",
    "\n",
    "# get yolo paremeters\n",
    "# output_sizes = net.output_sizes(input_size=image_shape[:2][::-1])[-1,:]\n",
    "output_sizes = np.array(result.shape[2:][::-1])\n",
    "del tensor\n",
    "del result\n",
    "\n",
    "print(\"Anchors: \")\n",
    "print(anchors) \n",
    "print(\"Output sizes: \")\n",
    "print(output_sizes) \n",
    "\n",
    "# CREATE GENERATORS\n",
    "def numpy_to_tensor(X,y,device=device):\n",
    "    return utils.data_to_tensor_v3(X,y,device)\n",
    "(None,None,None,None)\n",
    "grid_WH2 = image_shape[:2][::-1] // (2*output_sizes)\n",
    "\n",
    "val_generator = preprocessing.YoloDataGenerator(\n",
    "                            dataset_local_path,\n",
    "                            input_shape=image_shape,\n",
    "                            anchors=anchors,\n",
    "                            images_labes=[], \n",
    "                            batch_size=batch_size,\n",
    "                            name='ValGenerator', \n",
    "                            augmentator=None,\n",
    "                            output_size=output_sizes,\n",
    "                            after_load=after_load,\n",
    "                            # bbox_to_anchors=to_anchors_single,\n",
    "                            bbox_to_anchors=to_anchors_multi,\n",
    "                            )\n",
    "test_generator = preprocessing.YoloDataGenerator(\n",
    "                            dataset_local_path,\n",
    "                            input_shape=image_shape,\n",
    "                            anchors=anchors,\n",
    "                            images_labes=[], \n",
    "                            batch_size=batch_size,\n",
    "                            name='TestGenerator', \n",
    "                            augmentator=None,\n",
    "                            output_size=output_sizes,\n",
    "                            after_load=after_load,\n",
    "                            # bbox_to_anchors=to_anchors_single,\n",
    "                            bbox_to_anchors=to_anchors_multi,\n",
    "                            )\n",
    "\n",
    "_, val_set = folds.__getitem__(0, train_folds=4)\n",
    "val_generator.images_labes = val_set\n",
    "test_generator.images_labes = folds.test_set\n",
    "\n",
    "# decorator -> aplly anchor mul before metric calculation \n",
    "metric_iou = metrics.SingleObjectIOUsBasedMetrics(anchors, image_shape, device)\n",
    "def mean_iou(y_pred, y_ref, metric_iou=metric_iou, anchor_mul=anchor_mul):\n",
    "    y_pred = anchor_mul(y_pred)\n",
    "    return metric_iou(y_pred, y_ref)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QFuGuk2NB4fz",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNeeded to run of quantize.\\nfirst with quant_mode = 'calib'\\nsecond with quant_mode = 'test'\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def evaluate(model,\n",
    "             dataloader,\n",
    "             evaluator, fl_model=net\n",
    "             ):\n",
    "    with torch.no_grad():\n",
    "        score = 0.0\n",
    "        cntr = 0\n",
    "        for i in range(len(dataloader)):\n",
    "            XY = dataloader[i]\n",
    "            X = XY[0]\n",
    "            Y = XY[1]\n",
    "            L = X.shape[0]\n",
    "            y_pred = model(X)\n",
    "            score = score*cntr + X.shape[0]*evaluator(y_pred, Y)\n",
    "            cntr += X.shape[0]\n",
    "            score /= cntr\n",
    "            print(\"\\rEvaluation {}/{}. Score = {}\".format(i,len(dataloader), score),end='')\n",
    "        \n",
    "        print(\"\\rEvaluation {}/{}. Score = {}\".format(len(dataloader),len(dataloader), score),end='\\n')\n",
    "\n",
    "\n",
    "def quantize(float_model:torch.nn.Module, \n",
    "             input_shape:tuple,\n",
    "             quant_dir:str, \n",
    "             quant_mode:str, \n",
    "             device:torch.device,\n",
    "             dataloader,\n",
    "             evaluator):\n",
    "    \"\"\"\n",
    "    :param float_model: float model with loaded weights\n",
    "    :param input_shape: shape of input(CH,W,H)\n",
    "    :param quant_dir: path to directory with quantized model components\n",
    "    :param quant_mode: quant_mode in ['calib', 'test'] \n",
    "    :param data_loader: data_loader target is not needed - for 'calib' must be batch_size == 1\n",
    "    :param evaluator: fcn/obj like: fcn(y_pred, y_ref) -> float \n",
    "    \"\"\"\n",
    "    # available in docker or after packaging \n",
    "    # vitis-AI-tools/..../pytorch../pytorch_nndct\n",
    "    # and installing the package\n",
    "    from pytorch_nndct.apis import torch_quantizer, dump_xmodel\n",
    "    # model to device\n",
    "    model = float_model.to(device)\n",
    "    \n",
    "    # That was present in vai tutorial.\n",
    "    # I don't know if it affects to anything?\n",
    "    # Force to merge BN with CONV for better quantization accuracy\n",
    "    optimize = 1\n",
    "\n",
    "    rand_in = torch.randn((1,)+input_shape[-1:]+input_shape[:2])\n",
    "    print(\"get qunatizer start\")\n",
    "    try:\n",
    "        quantizer = torch_quantizer(\n",
    "            quant_mode, model, rand_in, output_dir=quant_dir, device=device)\n",
    "    except Exception as e:\n",
    "        print(\"exception:\")\n",
    "        print(e)\n",
    "        return\n",
    "    print(\"get qunatizer end\")\n",
    "        \n",
    "    print(\"get quantized model start\")\n",
    "    quantized_model = quantizer.quant_model\n",
    "    print(\"get quantized model end\")\n",
    "\n",
    "    # evaluate\n",
    "    print(\"testing st\")\n",
    "    evaluate(quantized_model, dataloader, evaluator)\n",
    "    print(\"testing end\")\n",
    "\n",
    "    # export config\n",
    "    if quant_mode == 'calib':\n",
    "        print(\"export config\")\n",
    "        quantizer.export_quant_config()\n",
    "        print(\"export config end\")\n",
    "    # export model\n",
    "    if quant_mode == 'test':\n",
    "        print(\"export xmodel\")\n",
    "        quantizer.export_xmodel(deploy_check=False, output_dir=quant_dir)\n",
    "        print(\"export xmodel end\")\n",
    "\n",
    "    return\n",
    "\n",
    "\"\"\"\n",
    "Needed to run of quantize.\n",
    "first with quant_mode = 'calib'\n",
    "second with quant_mode = 'test'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate float model on test dataset\n",
    "# evaluate(net,test_generator,evaluator=mean_iou)\n",
    "# Evaluation 6123/6124. Score = 0.6773354439616692\n",
    "# Evaluate float model on val dataset\n",
    "# evaluate(net,val_generator,evaluator=mean_iou)\n",
    "# Evaluation 279/1839. Score = 0.6722009609852523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only subset of val set\n",
    "# set whole dataset\n",
    "val_generator.images_labes = val_set\n",
    "# shuffle samples\n",
    "val_generator.on_epoch_end()\n",
    "# get subset (100) of samples\n",
    "subset = val_generator.images_labes[:1]\n",
    "val_generator.images_labes = subset\n",
    "# process only one image per forward\n",
    "val_generator.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "get qunatizer start\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Quant Module is in 'cpu'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Parsing Sequential...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Quantizable module is generated.(quant_dir/Sequential.py)\u001b[0m\n",
      "get qunatizer end\n",
      "get quantized model start\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Get module with quantization.\u001b[0m\n",
      "get quantized model end\n",
      "testing st\n",
      "Evaluation 1/1. Score = 0.9626518487930298\n",
      "testing end\n",
      "export config\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Exporting quant config.(quant_dir/quant_info.json)\u001b[0m\n",
      "export config end\n"
     ]
    }
   ],
   "source": [
    "# Quantize model - calib\n",
    "quantize(net, \n",
    "         image_shape,\n",
    "         quant_dir='quant_dir',\n",
    "         quant_mode='calib',\n",
    "         device=device,\n",
    "         dataloader=val_generator,\n",
    "         evaluator=mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get qunatizer start\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Quant Module is in 'cpu'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Parsing Sequential...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Quantizable module is generated.(quant_dir/Sequential.py)\u001b[0m\n",
      "get qunatizer end\n",
      "get quantized model start\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Get module with quantization.\u001b[0m\n",
      "get quantized model end\n",
      "testing st\n",
      "Evaluation 1/1. Score = 0.9626518487930298\n",
      "testing end\n",
      "export xmodel\n",
      "\n",
      "\u001b[0;32m[NNDCT_NOTE]: =>Converting to xmodel ...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Quantize model - test\n",
    "    quantize(net, \n",
    "             image_shape,\n",
    "             quant_dir='quant_dir',\n",
    "             quant_mode='test',\n",
    "             device=device,\n",
    "             dataloader=val_generator,\n",
    "             evaluator=mean_iou)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "except:\n",
    "    print(\"XD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vai_c_xir --xmodel quant_dir/Sequential_int.xmodel --arch arch.json --net_name LN7_VAI --output_dir  build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Quantize.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
